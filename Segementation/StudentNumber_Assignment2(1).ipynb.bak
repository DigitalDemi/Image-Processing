{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1c5b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (536,0,3) (536,442,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m I1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./male.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    102\u001b[0m I2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./female.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m merged \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(merged)\n\u001b[0;32m    107\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[5], line 82\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(BG, I1, I2)\u001b[0m\n\u001b[0;32m     80\u001b[0m roi1 \u001b[38;5;241m=\u001b[39m result[y1:y1\u001b[38;5;241m+\u001b[39mh1, x1:x1\u001b[38;5;241m+\u001b[39mw1]\n\u001b[0;32m     81\u001b[0m roi2 \u001b[38;5;241m=\u001b[39m result[y2:y2\u001b[38;5;241m+\u001b[39mh2, x2:x2\u001b[38;5;241m+\u001b[39mw2]\n\u001b[1;32m---> 82\u001b[0m roi1[:] \u001b[38;5;241m=\u001b[39m \u001b[43mroi1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask1_resized\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m I1_resized \u001b[38;5;241m*\u001b[39m mask1_resized\n\u001b[0;32m     83\u001b[0m roi2[:] \u001b[38;5;241m=\u001b[39m roi2 \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mask2_resized) \u001b[38;5;241m+\u001b[39m I2_resized \u001b[38;5;241m*\u001b[39m mask2_resized\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Convert to RGB for display\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (536,0,3) (536,442,3) "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def process_image(BG: np.ndarray, I1: np.ndarray, I2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Merges two people from green and white screen photos onto a background image,\n",
    "    making person 1 larger than person 2, and removing both green and white backgrounds.\n",
    "    \"\"\"\n",
    "    # Convert images to HSV color space for better color detection\n",
    "    hsv1 = cv2.cvtColor(I1, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(I2, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define color ranges for green and white in HSV\n",
    "    # Green color range\n",
    "    lower_green = np.array([35, 40, 40])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "    \n",
    "    # White color range\n",
    "    lower_white = np.array([0, 0, 200])\n",
    "    upper_white = np.array([180, 30, 255])\n",
    "    \n",
    "    # Create masks for green color\n",
    "    mask_green1 = cv2.inRange(hsv1, lower_green, upper_green)\n",
    "    mask_green2 = cv2.inRange(hsv2, lower_green, upper_green)\n",
    "    \n",
    "    # Create masks for white color\n",
    "    mask_white1 = cv2.inRange(hsv1, lower_white, upper_white)\n",
    "    mask_white2 = cv2.inRange(hsv2, lower_white, upper_white)\n",
    "    \n",
    "    # Combine green and white masks\n",
    "    mask1 = cv2.bitwise_or(mask_green1, mask_white1)\n",
    "    mask2 = cv2.bitwise_or(mask_green2, mask_white2)\n",
    "    \n",
    "    # Invert masks to get the foreground\n",
    "    mask1 = cv2.bitwise_not(mask1)\n",
    "    mask2 = cv2.bitwise_not(mask2)\n",
    "    \n",
    "    # Add some blur to smooth edges\n",
    "    mask1 = cv2.GaussianBlur(mask1, (5, 5), 0)\n",
    "    mask2 = cv2.GaussianBlur(mask2, (5, 5), 0)\n",
    "    \n",
    "    # Convert masks to 3 channels\n",
    "    mask1_3d = cv2.cvtColor(mask1, cv2.COLOR_GRAY2BGR) / 255.0\n",
    "    mask2_3d = cv2.cvtColor(mask2, cv2.COLOR_GRAY2BGR) / 255.0\n",
    "    \n",
    "    # Resize images to be proportional to background width\n",
    "    height, width = BG.shape[:2]\n",
    "    \n",
    "    # Set different scaling factors for each person\n",
    "    scaling_factor1 = 0.8 # Person 1 will be 95% of background width\n",
    "    scaling_factor2 = 1   # Person 2 will be 70% of background width\n",
    "    \n",
    "    # Compute new widths\n",
    "    new_width1 = int(width * scaling_factor1)\n",
    "    new_width2 = int(width * scaling_factor2)\n",
    "    \n",
    "    # Compute aspect ratios\n",
    "    ratio1 = I1.shape[1] / I1.shape[0]  \n",
    "    ratio2 = I2.shape[1] / I2.shape[0]\n",
    "    \n",
    "    # Compute new heights\n",
    "    new_height1 = int(new_width1 / ratio1)\n",
    "    new_height2 = int(new_width2 / ratio2)\n",
    "    \n",
    "    # Resize images and masks\n",
    "    I1_resized = cv2.resize(I1, (new_width1, new_height1))\n",
    "    mask1_resized = cv2.resize(mask1_3d, (new_width1, new_height1))\n",
    "    \n",
    "    I2_resized = cv2.resize(I2, (new_width2, new_height2))\n",
    "    mask2_resized = cv2.resize(mask2_3d, (new_width2, new_height2))\n",
    "    \n",
    "    # Create copy of background\n",
    "    result = BG.copy()\n",
    "    \n",
    "    # Calculate positions for placing people\n",
    "    y_offset1 = height - new_height1  # Place at bottom\n",
    "    y_offset2 = height - new_height2\n",
    "    x_offset1 = width // 4 - new_width1 // 2  # Left quarter\n",
    "    x_offset2 = 3 * width // 4 - new_width2 // 2  # Right quarter\n",
    "    \n",
    "    # Ensure offsets are within image bounds\n",
    "    x_offset1 = max(0, min(x_offset1, width - new_width1))\n",
    "    x_offset2 = max(0, min(x_offset2, width - new_width2))\n",
    "    y_offset1 = max(0, min(y_offset1, height - new_height1))\n",
    "    y_offset2 = max(0, min(y_offset2, height - new_height2))\n",
    "    \n",
    "    # Get regions of interest\n",
    "    roi1 = result[y_offset1:y_offset1 + new_height1, x_offset1:x_offset1 + new_width1]\n",
    "    roi2 = result[y_offset2:y_offset2 + new_height2, x_offset2:x_offset2 + new_width2]\n",
    "    \n",
    "    # Blend images\n",
    "    roi1[:] = roi1 * (1 - mask1_resized) + I1_resized * mask1_resized\n",
    "    roi2[:] = roi2 * (1 - mask2_resized) + I2_resized * mask2_resized\n",
    "\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Please DO NOT change any of the code below. All modifications to this template should\n",
    "# occur inside the **process_image** function\n",
    "\n",
    "\n",
    "BG = cv2.imread('./background.jpg')\n",
    "I1 = cv2.imread('./male.jpg')\n",
    "I2 = cv2.imread('./female.jpg')\n",
    "\n",
    "merged = process_image(BG, I1, I2)\n",
    "\n",
    "plt.imshow(merged)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-processing-psVIxX7P-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
